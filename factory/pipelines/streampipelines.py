from factory.pipelines.pipeline import MetaPipeline
from factory.connectors.connectors import KafkaConnector
from factory import settings
import asyncio
import random
import logging

logger = logging.getLogger('AioETL')

class StreamPipeline(metaclass=MetaPipeline):
    '''stream pipeline is for transfer results after middleware chain or logger
       all generated by the factory information should pass this pipeline
    '''
    def __init__(self):
        pass

    @staticmethod
    async def generate_whatever():
        while True:
            yield {'mock': random.randrange(0, 1000)}
            await asyncio.sleep(0.1)


    async def start(self):
        pass


class KafkaStreamPipeline(StreamPipeline):

    def __init__(self):
        super().__init__()

    async def start(self, topic, queue):
        self.pipeline = KafkaConnector(topic)
        self.stream_queue = queue
        await self.pipeline.start_producer()
        logger.info('Stream pipeline {} ready'.format(self.__class__.__name__))
        while True:
            m = await self.stream_queue.get()
            if m is None: break
            await self.pipeline.producer.send(settings.STREAM_TOPIC, value=m)
            await self.pipeline.producer.flush()

